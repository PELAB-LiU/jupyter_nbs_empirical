{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, ZeroPadding2D,\\\n     Flatten, BatchNormalization, AveragePooling2D, Dense, Activation, Add, Dropout\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras import activations\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom tensorflow.keras.regularizers import l2\nfrom tensorflow.keras.layers import Convolution2D\nfrom tensorflow.keras.applications.mobilenet_v2 import MobileNetV2\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nimport numpy as np\n\nimport random\nimport shutil\nimport cv2\nimport os\nfrom PIL import Image","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Increasing the image size didn't result in increasing the training accuracy\nIMAGE_WIDTH = 600    \nIMAGE_HEIGHT = 800\nIMAGE_SIZE=(IMAGE_WIDTH, IMAGE_HEIGHT)\nIMAGE_CHANNELS = 3","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train_val_generators(TRAINING_DIR, VALIDATION_DIR):\n  \"\"\"\n  Creates the training and validation data generators\n  \n  Args:\n    TRAINING_DIR (string): directory path containing the training images\n    VALIDATION_DIR (string): directory path containing the testing/validation images\n    \n  Returns:\n    train_generator, validation_generator - tuple containing the generators\n  \"\"\"\n  ### START CODE HERE\n\n  # Instantiate the ImageDataGenerator class (don't forget to set the arguments to augment the images)\n  train_datagen = ImageDataGenerator(rescale=1/255,\n                                     rotation_range=40,\n                                     width_shift_range=0.2,\n                                     height_shift_range=0.2,\n                                     shear_range=0.2,\n                                     zoom_range=0.2,\n#                                      brightness_range=[0.7,1.5],\n                                     horizontal_flip=True,\n                                     vertical_flip=True,\n                                     fill_mode='nearest')\n\n  # Pass in the appropriate arguments to the flow_from_directory method\n  train_generator = train_datagen.flow_from_directory(directory=TRAINING_DIR,\n                                                      batch_size=10,\n                                                      class_mode='categorical',\n                                                      target_size=(IMAGE_WIDTH, IMAGE_HEIGHT))\n\n  # Instantiate the ImageDataGenerator class (don't forget to set the rescale argument)\n  validation_datagen = ImageDataGenerator(rescale=1/255)\n\n  # Pass in the appropriate arguments to the flow_from_directory method\n  validation_generator = validation_datagen.flow_from_directory(directory=VALIDATION_DIR,\n                                                                batch_size=10,\n                                                                class_mode='categorical',\n                                                                target_size=(IMAGE_WIDTH, IMAGE_HEIGHT))\n  ### END CODE HERE\n  return train_generator, validation_generator","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Test generators\nROOT_DIR = \"/kaggle/input/oil-palm-class\"\nTRAINING_DIR = os.path.join(ROOT_DIR, \"train\")\nVALIDATION_DIR = os.path.join(ROOT_DIR, \"valid\")\n\ntrain_generator, validation_generator = train_val_generators(TRAINING_DIR, VALIDATION_DIR)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pre_trained_model = MobileNetV2(input_shape =(IMAGE_WIDTH, IMAGE_HEIGHT, IMAGE_CHANNELS), include_top = False)\nfor layer in pre_trained_model.layers:\n    layer.trainable = False  \npre_trained_model.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#MobileNet Model\nx=Flatten()(pre_trained_model.output)\n\n#Fully Connection Layers\n# FC1\nx=Dense(512, activation=\"relu\")(x)\nx=Dense(256, activation=\"relu\")(x)\n#Dropout to avoid overfitting effect\nx=Dropout(0.2)(x)\n\n# FC2\nx=Dense(128, activation=\"relu\")(x)\n\n\n#output layer\nx=Dense(6,activation=\"sigmoid\")(x)\n\n\nmodel = Model(pre_trained_model.input,x)\n\nmodel.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras import backend as K\n\ndef recall_m(y_true, y_pred):\n    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n    recall = true_positives / (possible_positives + K.epsilon())\n    return recall\n\ndef precision_m(y_true, y_pred):\n    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n    precision = true_positives / (predicted_positives + K.epsilon())\n    return precision\n\ndef f1_m(y_true, y_pred):\n    precision = precision_m(y_true, y_pred)\n    recall = recall_m(y_true, y_pred)\n    return 2*((precision*recall)/(precision+recall+K.epsilon()))\n\nmodel.compile(optimizer = 'adam', loss='categorical_crossentropy', metrics = ['acc', f1_m])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def earlystop(mode):\n  if mode=='acc':\n    estop = tf.keras.callbacks.EarlyStopping(monitor='val_acc', patience=30, mode='max')\n  elif mode=='loss':\n    estop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=30, mode='min')\n  return estop \n\nearlystop = earlystop('acc')\n\ncheckpoint = tf.keras.callbacks.ModelCheckpoint(\"/kaggle/working/best_model_train3\",\n                                            save_best_only=True, monitor='val_loss', mode=\"min\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"batch_size = 20\nsteps_per_epoch = 374/batch_size\nvalidation_steps = 360/batch_size\nclassifier_history = model.fit(train_generator, \n                                epochs=200, \n                                steps_per_epoch=steps_per_epoch,\n                                validation_steps=validation_steps, \n                                validation_data=validation_generator, \n                                callbacks=[checkpoint])","metadata":{"execution":{"iopub.status.busy":"2023-05-16T00:37:59.377760Z","iopub.execute_input":"2023-05-16T00:37:59.378340Z","iopub.status.idle":"2023-05-16T00:37:59.682996Z","shell.execute_reply.started":"2023-05-16T00:37:59.378285Z","shell.execute_reply":"2023-05-16T00:37:59.681202Z"},"trusted":true},"execution_count":2,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[2], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m steps_per_epoch \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m374\u001b[39m\u001b[38;5;241m/\u001b[39mbatch_size\n\u001b[1;32m      3\u001b[0m validation_steps \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m360\u001b[39m\u001b[38;5;241m/\u001b[39mbatch_size\n\u001b[0;32m----> 4\u001b[0m classifier_history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241m.\u001b[39mfit(train_generator, \n\u001b[1;32m      5\u001b[0m                                 epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m200\u001b[39m, \n\u001b[1;32m      6\u001b[0m                                 steps_per_epoch\u001b[38;5;241m=\u001b[39msteps_per_epoch,\n\u001b[1;32m      7\u001b[0m                                 validation_steps\u001b[38;5;241m=\u001b[39mvalidation_steps, \n\u001b[1;32m      8\u001b[0m                                 validation_data\u001b[38;5;241m=\u001b[39mvalidation_generator, \n\u001b[1;32m      9\u001b[0m                                 callbacks\u001b[38;5;241m=\u001b[39m[checkpoint])\n","\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"],"ename":"NameError","evalue":"name 'model' is not defined","output_type":"error"}]},{"cell_type":"code","source":"import os\nos.chdir(r'/kaggle/working')\n\n!tar -czf best_model_train3.tar.gz best_model_train3\n\nfrom IPython.display import FileLink\n\nFileLink(r'best_model_train3.tar.gz')","metadata":{"execution":{"iopub.status.busy":"2023-05-16T00:38:43.897380Z","iopub.execute_input":"2023-05-16T00:38:43.897867Z","iopub.status.idle":"2023-05-16T00:43:09.759710Z","shell.execute_reply.started":"2023-05-16T00:38:43.897803Z","shell.execute_reply":"2023-05-16T00:43:09.757947Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"/kaggle/working/best_model_train3.tar.gz","text/html":"<a href='best_model_train3.tar.gz' target='_blank'>best_model_train3.tar.gz</a><br>"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}