{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0d037800",
   "metadata": {},
   "source": [
    "# Data preparation of labels from manual labeling and reviewing process\n",
    "\n",
    "of the sampled crashes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c824705",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import importlib\n",
    "# importlib.reload(config)\n",
    "# import utils.config as config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "851f4778",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "path_default=WindowsPath('C:/Users/yirwa29/Downloads/data_jupyter_nbs_empirical')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yirwa29\\AppData\\Local\\anaconda3\\envs\\chatgpt\\Lib\\site-packages\\openpyxl\\worksheet\\_reader.py:329: UserWarning: Data Validation extension is not supported and will be removed\n",
      "  warn(msg)\n",
      "C:\\Users\\yirwa29\\AppData\\Local\\Temp\\ipykernel_6780\\251241085.py:15: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_mlerr_labels['other'].replace([0], \"\", inplace=True)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import utils.config as config\n",
    "import numpy as np\n",
    "\n",
    "# manually labeled\n",
    "df_mlerr_labels = pd.read_excel(config.path_default.joinpath('Manual_labeing/cluster_sampled_labeled.xlsx'),\n",
    "                                sheet_name = \"Del-All\",\n",
    "                                keep_default_na=False)\n",
    "\n",
    "df_mlerr_label_config = pd.read_excel(config.path_default.joinpath('Manual_labeing/cluster_sampled_labeled.xlsx'),\n",
    "                                sheet_name = \"Config\",\n",
    "                                keep_default_na=False)\n",
    "df_mlerr_label_config_exclude = [\"Review_res\", \"Responsible\"]\n",
    "df_mlerr_label_config.drop(df_mlerr_label_config_exclude, axis=1, inplace=True)\n",
    "df_mlerr_labels['other'].replace([0], \"\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b608e516",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "++++Labels in the config but are not used in manual labeling++++\n",
      "label_root_cause\n",
      "['intentional', '']\n",
      "label_ML_pipeline\n",
      "['not-applicable (sub-labels needed, e.g., tutorials, physics simulation, ..)', 'unknown', 'not applicable - tutorial notebook', 'not applicable - physics', 'not applicable - education', '']\n",
      "label_if_ML_bug\n",
      "['unknown', '']\n",
      "label_refined_exp_type\n",
      "['constraint violation (database)']\n",
      "label_if_runinfo_help\n",
      "['']\n",
      "label_if_code_error_align\n",
      "['']\n",
      "label_if_error_chain\n",
      "['unknown', '']\n",
      "other\n",
      "['intentional', 'should exclude']\n",
      "\n",
      "++++[Should not happen]Labels used in manual labeling but not in config++++\n",
      "label_root_cause\n",
      "[]\n",
      "label_ML_pipeline\n",
      "[]\n",
      "label_if_ML_bug\n",
      "[]\n",
      "label_refined_exp_type\n",
      "[]\n",
      "label_if_runinfo_help\n",
      "[]\n",
      "label_if_code_error_align\n",
      "[]\n",
      "label_if_error_chain\n",
      "[]\n",
      "other\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "import utils.data_labeled_process as data_labeled_process\n",
    "\n",
    "data_labeled_process.labeled_data_config_clean(df_mlerr_labels, \n",
    "                                               df_mlerr_label_config, \n",
    "                                               save_config_path = config.path_default.joinpath(\"Manual_labeing/cluster_sampled_labeled_config.xlsx\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f717bf9e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Map the summarized config to config and the data\n",
    "data_labeled_process.labeled_data_config_sum(df_mlerr_labels, \n",
    "                                             df_mlerr_label_config, \n",
    "                                             save_data_path = config.path_default.joinpath(\"Manual_labeing/cluster_sampled_labeled_config_sum.xlsx\"), \n",
    "                                             save_config_path = config.path_default.joinpath(\"Manual_labeing/cluster_sampled_labeled_sum.xlsx\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a47ca225",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mlerr_labels.to_excel(config.path_default.joinpath(\"Manual_labeing/cluster_sampled_labeled_processed.xlsx\"), index=False, engine='xlsxwriter')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
