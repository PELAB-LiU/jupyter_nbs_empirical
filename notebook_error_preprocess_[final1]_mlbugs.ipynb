{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a976ac74",
   "metadata": {},
   "source": [
    "## Mark ML bugs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b94c86f",
   "metadata": {},
   "source": [
    "We define ML bugs as any bugs that are related to a ML library.\n",
    "\n",
    "The extraction of the linked ML libraries to exceptions or errors are: /exception_to_library_linker\n",
    "\n",
    "The filtered notebooks/errors (Final dataset) can be obtained by: \n",
    "\n",
    "    df_err.is_MLnb&df_err.is_relevant&df_err.if_ast==1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f60e92b",
   "metadata": {},
   "source": [
    "### 1. nb errors in Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "33a52057",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "path_default=WindowsPath('C:/Users/yirwa29/Downloads/Dataset-Nb')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import config, util\n",
    "\n",
    "path_err = config.path_kaggle_error_process.joinpath('nberror_k_eid_p.xlsx')\n",
    "path_exp_libs = config.path_default.joinpath('links_exceptions_to_libraries.jsonl')\n",
    "df_err = pd.read_excel(path_err)\n",
    "df_err = df_err[df_err.is_MLnb&df_err.is_relevant&df_err.if_ast==1.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "787fc9a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_exp_mllib = util.get_exp_mllib(path_exp_libs, df_err)\n",
    "df_exp_mllib = pd.DataFrame(res_exp_mllib.items(), columns=[\"eid\", \"exp_mllib\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ff0c8f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_err_merged = pd.merge(df_err, df_exp_mllib, on=\"eid\", how=\"left\")\n",
    "df_err_merged = df_err_merged.drop_duplicates(subset='eid', keep=\"first\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ef47fbc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 68.07% (1842) notebooks existing ML bugs\n",
      "There are 65.11% (2538) errors are ML bugs\n"
     ]
    }
   ],
   "source": [
    "# percentages on the notebooks (is_MLnb&is_relevant&if_ast)\n",
    "print(\"There are {:.2%} ({}) notebooks existing ML bugs\".format(\n",
    "    df_err_merged[~df_err_merged.exp_mllib.isnull()].fname.nunique()/df_err_merged.fname.nunique(),\n",
    "    df_err_merged[~df_err_merged.exp_mllib.isnull()].fname.nunique()))\n",
    "# percentages on the errors (is_MLnb&is_relevant&if_ast)\n",
    "print(\"There are {:.2%} ({}) errors are ML bugs\".format(\n",
    "    df_err_merged[~df_err_merged.exp_mllib.isnull()].eid.nunique()/df_err_merged.eid.nunique(),\n",
    "    df_err_merged[~df_err_merged.exp_mllib.isnull()].eid.nunique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d0d16a9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1839 0.6806069578090304\n",
      "2534 0.6510791366906474\n"
     ]
    }
   ],
   "source": [
    "# python 3\n",
    "tmp_py3 = df_err_merged[(df_err_merged.python_version==3) & (~df_err_merged.exp_mllib.isnull())].fname.nunique()\n",
    "tmp1_py3 = df_err_merged[(df_err_merged.python_version==3) & (~df_err_merged.exp_mllib.isnull())].eid.nunique()\n",
    "print(tmp_py3, tmp_py3/df_err_merged[df_err_merged.python_version==3].fname.nunique())\n",
    "print(tmp1_py3, tmp1_py3/df_err_merged[df_err_merged.python_version==3].eid.nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c6426e22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 0.75\n",
      "4 0.6666666666666666\n"
     ]
    }
   ],
   "source": [
    "# python -1 / unknown\n",
    "tmp_pynone = df_err_merged[(df_err_merged.python_version!=3) & (~df_err_merged.exp_mllib.isnull())].fname.nunique()\n",
    "tmp1_pynone = df_err_merged[(df_err_merged.python_version!=3) & (~df_err_merged.exp_mllib.isnull())].eid.nunique()\n",
    "print(tmp_pynone, tmp_pynone/df_err_merged[df_err_merged.python_version!=3].fname.nunique())\n",
    "print(tmp1_pynone, tmp1_pynone/df_err_merged[df_err_merged.python_version!=3].eid.nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a0e2f308",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_err_merged.loc[:,\"exp_mllib_extracted\"] = df_err_merged.apply(util.extract_libs_from_exp_mllib, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b84f873f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# exclude: 'if_ast', 'is_MLnb', 'is_relevant'\n",
    "df_err_merged[['fname', 'eid', 'ename', 'evalue', 'traceback', \n",
    "               'ename_mapped','imports', 'lib_alias',\n",
    "               'exp_mllib', 'exp_mllib_extracted',\n",
    "               'python_version']].to_excel(config.path_kaggle_error_process.joinpath('nberror_k_eid_p_mlbugs.xlsx'),\n",
    "                                           index=False, engine='xlsxwriter')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32e802be",
   "metadata": {},
   "source": [
    "### 2. nb errors in Github"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a7d9d206",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "path_default=WindowsPath('C:/Users/yirwa29/Downloads/Dataset-Nb')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import config, util\n",
    "\n",
    "path2_err = config.path_github_error_process.joinpath('nberror_g_all_eid_p.xlsx')\n",
    "path_exp_libs = config.path_default.joinpath('links_exceptions_to_libraries.jsonl')\n",
    "\n",
    "df2_err = pd.read_excel(path2_err)\n",
    "df2_err = df2_err[df2_err.is_MLnb&df2_err.is_relevant&df2_err.if_ast==1.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "501a93f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_exp_mllib = util.get_exp_mllib(path_exp_libs, df2_err)\n",
    "df_exp_mllib = pd.DataFrame(res_exp_mllib.items(), columns=[\"eid\", \"exp_mllib\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a464e76a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_err_merged = pd.merge(df2_err, df_exp_mllib, on=\"eid\", how=\"left\")\n",
    "df_err_merged = df_err_merged.drop_duplicates(subset='eid', keep=\"first\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5cdfd88e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 40.30% (26910) notebooks existing ML bugs\n",
      "There are 36.97% (36139) errors are ML bugs\n"
     ]
    }
   ],
   "source": [
    "# percentages on the notebooks (is_MLnb&is_relevant&if_ast)\n",
    "print(\"There are {:.2%} ({}) notebooks existing ML bugs\".format(\n",
    "    df_err_merged[~df_err_merged.exp_mllib.isnull()].fname.nunique()/df_err_merged.fname.nunique(),\n",
    "    df_err_merged[~df_err_merged.exp_mllib.isnull()].fname.nunique()))\n",
    "# percentages on the errors (is_MLnb&is_relevant&if_ast)\n",
    "print(\"There are {:.2%} ({}) errors are ML bugs\".format(\n",
    "    df_err_merged[~df_err_merged.exp_mllib.isnull()].eid.nunique()/df_err_merged.eid.nunique(),\n",
    "    df_err_merged[~df_err_merged.exp_mllib.isnull()].eid.nunique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2537142e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23880 0.4245408807267685\n",
      "32257 0.38970437219866383\n"
     ]
    }
   ],
   "source": [
    "# python 3\n",
    "tmp_py3 = df_err_merged[(df_err_merged.python_version==3) & (~df_err_merged.exp_mllib.isnull())].fname.nunique()\n",
    "tmp1_py3 = df_err_merged[(df_err_merged.python_version==3) & (~df_err_merged.exp_mllib.isnull())].eid.nunique()\n",
    "print(tmp_py3, tmp_py3/df_err_merged[df_err_merged.python_version==3].fname.nunique())\n",
    "print(tmp1_py3, tmp1_py3/df_err_merged[df_err_merged.python_version==3].eid.nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "39a87a18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "431 0.1186020913593836\n",
      "522 0.1019730416096894\n"
     ]
    }
   ],
   "source": [
    "# python 2\n",
    "tmp_py2 = df_err_merged[(df_err_merged.python_version==2) & (~df_err_merged.exp_mllib.isnull())].fname.nunique()\n",
    "tmp1_py2 = df_err_merged[(df_err_merged.python_version==2) & (~df_err_merged.exp_mllib.isnull())].eid.nunique()\n",
    "print(tmp_py2, tmp_py2/df_err_merged[df_err_merged.python_version==2].fname.nunique())\n",
    "print(tmp1_py2, tmp1_py2/df_err_merged[df_err_merged.python_version==2].eid.nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f6b5b88e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2599 0.37732288037166084\n",
      "3360 0.3408053555127295\n"
     ]
    }
   ],
   "source": [
    "# python -1 / unknown\n",
    "tmp_pynone = df_err_merged[(df_err_merged.python_version==-1) & (~df_err_merged.exp_mllib.isnull())].fname.nunique()\n",
    "tmp1_pynone = df_err_merged[(df_err_merged.python_version==-1) & (~df_err_merged.exp_mllib.isnull())].eid.nunique()\n",
    "print(tmp_pynone, tmp_pynone/df_err_merged[df_err_merged.python_version==-1].fname.nunique())\n",
    "print(tmp1_pynone, tmp1_pynone/df_err_merged[df_err_merged.python_version==-1].eid.nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d67e31fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_err_merged.loc[:,\"exp_mllib_extracted\"] = df_err_merged.apply(util.extract_libs_from_exp_mllib, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a1d04456",
   "metadata": {},
   "outputs": [],
   "source": [
    "# exclude: 'if_ast', 'is_MLnb', 'is_relevant', 'python_version==3'\n",
    "df_err_merged[['fname', 'eid', 'ename', 'evalue', 'traceback', \n",
    "               'ename_mapped','imports', 'lib_alias',\n",
    "               'exp_mllib', 'exp_mllib_extracted',\n",
    "               'python_version']].to_excel(config.path_github_error_process.joinpath('nberror_g_all_eid_p_mlbugs.xlsx'),\n",
    "                                           index=False, engine='xlsxwriter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aaf9d9ee",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00000-1171-strax-demo.ipynb\n",
      "b63153b4-9eee-385e-b788-c093678c5068\n",
      "---------------------------------------------------------------------------\n",
      "DataNotAvailable                          Traceback (most recent call last)\n",
      "Input In [32], in <module>\n",
      "----> 1 st.event_scatter(run_id, config=dict(s1_min_n_channelz=10), seconds_range=[0,60])\n",
      "\n",
      "File ~/software/dev_strax/straxen/straxen/mini_analysis.py:106, in mini_analysis.<locals>.decorator.<locals>.wrapped_f(context, run_id, **kwargs)\n",
      "    100         kwargs[dkind] = strax.apply_selection(\n",
      "    101             kwargs[dkind],\n",
      "    102             selection_str=kwargs['selection_str'],\n",
      "    103             time_range=kwargs['time_range'],\n",
      "    104             time_selection=kwargs['time_selection'])\n",
      "    105     else:\n",
      "--> 106         kwargs[dkind] = context.get_array(\n",
      "    107             run_id,\n",
      "    108             dtypes,\n",
      "    109             selection_str=kwargs['selection_str'],\n",
      "    110             time_range=kwargs['time_range'],\n",
      "    111             time_selection=kwargs['time_selection'],\n",
      "    112             # Arguments for new context, if needed\n",
      "    113             config=kwargs.get('config'),\n",
      "    114             register=kwargs.get('register'),\n",
      "    115             storage=kwargs.get('storage', tuple()),\n",
      "    116             progress_bar=False,\n",
      "    117         )\n",
      "    119 # If user did not give time kwargs, but the function expects\n",
      "    120 # a time_range, try to add one based on the time range of the data\n",
      "    121 base_dkind = list(deps_by_kind.keys())[0]\n",
      "\n",
      "File ~/software/dev_strax/strax/strax/context.py:1406, in Context.get_array(self, run_id, targets, save, max_workers, **kwargs)\n",
      "   1399 else:\n",
      "   1400     source = self.get_iter(\n",
      "   1401         run_ids[0],\n",
      "   1402         targets,\n",
      "   1403         save=save,\n",
      "   1404         max_workers=max_workers,\n",
      "   1405         **kwargs)\n",
      "-> 1406     results = [x.data for x in source]\n",
      "   1408 results = np.concatenate(results)\n",
      "   1409 return results\n",
      "\n",
      "File ~/software/dev_strax/strax/strax/context.py:1406, in <listcomp>(.0)\n",
      "   1399 else:\n",
      "   1400     source = self.get_iter(\n",
      "   1401         run_ids[0],\n",
      "   1402         targets,\n",
      "   1403         save=save,\n",
      "   1404         max_workers=max_workers,\n",
      "   1405         **kwargs)\n",
      "-> 1406     results = [x.data for x in source]\n",
      "   1408 results = np.concatenate(results)\n",
      "   1409 return results\n",
      "\n",
      "File ~/software/dev_strax/strax/strax/context.py:1234, in Context.get_iter(self, run_id, targets, save, max_workers, time_range, seconds_range, time_within, time_selection, selection_str, keep_columns, drop_columns, allow_multiple, progress_bar, _chunk_number, **kwargs)\n",
      "   1225     elif (self.context_config['timeout'] > 7200 or (\n",
      "   1226             self.context_config['allow_lazy'] and\n",
      "   1227             not self.context_config['allow_multiprocess'])):\n",
      "   1228         # For allow_multiple we don't want allow this when in lazy mode\n",
      "   1229         # with long timeouts (lazy-mode is disabled if multiprocessing\n",
      "   1230         # so if that is activated, we can also continue)\n",
      "   1231         raise RuntimeError(f'Cannot allow_multiple in lazy mode or '\n",
      "   1232                            f'with long timeouts.')\n",
      "-> 1234 components = self.get_components(run_id,\n",
      "   1235                                  targets=targets,\n",
      "   1236                                  save=save,\n",
      "   1237                                  time_range=time_range,\n",
      "   1238                                  chunk_number=_chunk_number)\n",
      "   1240 # Cleanup the temp plugins\n",
      "   1241 for k in list(self._plugin_class_registry.keys()):\n",
      "\n",
      "File ~/software/dev_strax/strax/strax/context.py:979, in Context.get_components(self, run_id, targets, save, time_range, chunk_number)\n",
      "    975             savers = self._add_saver(savers, d_to_save, target_plugin,\n",
      "    976                                      _is_superrun, loading_this_data)\n",
      "    978 for target_i in targets:\n",
      "--> 979     check_cache(target_i)\n",
      "    980 plugins = to_compute\n",
      "    982 intersec = list(plugins.keys() & loaders.keys())\n",
      "\n",
      "File ~/software/dev_strax/strax/strax/context.py:894, in Context.get_components.<locals>.check_cache(target_i)\n",
      "    891     if target_plugin.save_when[target_i] == strax.SaveWhen.TARGET:\n",
      "    892         error_message += (f\"\\nFirst run st.make({run_id}, \"\n",
      "    893                           f\"{target_i}) to make {target_i}.\")\n",
      "--> 894     raise strax.DataNotAvailable(error_message)\n",
      "    895 if '*' in self.context_config['forbid_creation_of']:\n",
      "    896     raise strax.DataNotAvailable(\n",
      "    897         f\"{target_i} for {run_id} not found in any storage, and \"\n",
      "    898         \"your context specifies no new data can be created.\")\n",
      "\n",
      "DataNotAvailable: Time range selection assumes data is already available, but event_info for 038769 is not.\n"
     ]
    }
   ],
   "source": [
    "tmp_exp = df_err_merged[(df_err_merged.python_version==3) & (df_err_merged.exp_mllib.isnull())].iloc[5]\n",
    "print(tmp_exp.fname)\n",
    "print(tmp_exp.eid)\n",
    "util.print_traceback(tmp_exp.traceback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4c834413",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00000-132-twitter-sentiment.ipynb\n",
      "89c3847e-55fd-302b-8b88-d7d60c448f63\n",
      "---------------------------------------------------------------------------\n",
      "NameError                                 Traceback (most recent call last)\n",
      "<ipython-input-47-b10598c39407> in <module>()\n",
      "     13 # Save a trained model, configuration and tokenizer using `save_pretrained()`.\n",
      "     14 # They can then be reloaded using `from_pretrained()`\n",
      "---> 15 model_to_save = model.module if hasattr(model, 'module') else model  # Take care of distributed/parallel training\n",
      "     16 model_to_save.save_pretrained(output_dir)\n",
      "     17 tokenizer.save_pretrained(output_dir)\n",
      "\n",
      "NameError: name 'model' is not defined\n"
     ]
    }
   ],
   "source": [
    "tmp_exp = df_err_merged[(df_err_merged.python_version==3) & (df_err_merged.exp_mllib.isnull())].iloc[6]\n",
    "print(tmp_exp.fname)\n",
    "print(tmp_exp.eid)\n",
    "util.print_traceback(tmp_exp.traceback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c68367e9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
