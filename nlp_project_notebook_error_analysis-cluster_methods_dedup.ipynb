{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "47f41d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import importlib\n",
    "# importlib.reload(cluster_util)\n",
    "# import cluster_util"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4566c1f6",
   "metadata": {},
   "source": [
    "# Notebook error analysis \n",
    "\n",
    "## Refining error types - Vectorization and clustering method selection\n",
    "\n",
    "\n",
    "use the combined dedupped GitHub + Kaggle error dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7af3f2db",
   "metadata": {},
   "source": [
    "### Clustering value errors\n",
    "\n",
    "load tokenized error dataset, evalue_tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e2bdfbe2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yirwa29\\AppData\\Local\\anaconda3\\envs\\chatgpt\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "path_default=WindowsPath('C:/Users/yirwa29/Downloads/Dataset-Nb')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import cluster_util, config\n",
    "\n",
    "path_res = config.path_default.joinpath(\"nlpproject\")\n",
    "df_mlerr_mlbugs_unique = pd.read_excel(config.path_default.joinpath(\"data_dedup_cluster/df_err_processed_pregroup_dedup.xlsx\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b0fbbfeb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7405"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "err_descs = df_mlerr_mlbugs_unique['evalue_processed'].values.astype('U')\n",
    "err_descs.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96a1a12a",
   "metadata": {},
   "source": [
    "### 1 Vectorization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2f75ef1",
   "metadata": {},
   "source": [
    "##### 2. sentence transformers\n",
    "\n",
    "https://github.com/UKPLab/sentence-transformers\n",
    "\n",
    "https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2\n",
    "\n",
    "sentence to vector, dimension -384\n",
    "\n",
    "different processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2be86b73",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "modules.json: 100%|███████████████████████████████████████████████████████████████████████████| 349/349 [00:00<?, ?B/s]\n",
      "C:\\Users\\yirwa29\\AppData\\Local\\anaconda3\\envs\\chatgpt\\Lib\\site-packages\\huggingface_hub\\file_download.py:147: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\yirwa29\\.cache\\huggingface\\hub. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "config_sentence_transformers.json: 100%|██████████████████████████████████████████████████████| 116/116 [00:00<?, ?B/s]\n",
      "README.md: 100%|██████████████████████████████████████████████████████████████████████████| 10.7k/10.7k [00:00<?, ?B/s]\n",
      "sentence_bert_config.json: 100%|████████████████████████████████████████████████████████████| 53.0/53.0 [00:00<?, ?B/s]\n",
      "config.json: 100%|█████████████████████████████████████████████████████████████████████| 612/612 [00:00<00:00, 902kB/s]\n",
      "model.safetensors: 100%|██████████████████████████████████████████████████████████| 90.9M/90.9M [00:07<00:00, 12.6MB/s]\n",
      "tokenizer_config.json: 100%|██████████████████████████████████████████████████████████████████| 350/350 [00:00<?, ?B/s]\n",
      "vocab.txt: 100%|████████████████████████████████████████████████████████████████████| 232k/232k [00:00<00:00, 2.08MB/s]\n",
      "tokenizer.json: 100%|███████████████████████████████████████████████████████████████| 466k/466k [00:00<00:00, 4.21MB/s]\n",
      "special_tokens_map.json: 100%|████████████████████████████████████████████████████████████████| 112/112 [00:00<?, ?B/s]\n",
      "1_Pooling/config.json: 100%|██████████████████████████████████████████████████████████████████| 190/190 [00:00<?, ?B/s]\n"
     ]
    }
   ],
   "source": [
    "# df_mlerr_mlbugs_unique['evalue_tokenized_transformer'] = df_mlerr_mlbugs_unique['evalue'].apply(cluster_util.preprocess_text_transformer)\n",
    "\n",
    "err_descs1 = df_mlerr_mlbugs_unique['evalue_processed'].values.astype('U')\n",
    "X_transformers = cluster_util.vectorizer_sentence2vec(err_descs1)\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "with open(path_res.joinpath(\"df_err_processed_pregroup_dedup_embeddings_transformers.txt\"), 'wb') as f:\n",
    "    np.save(f, X_transformers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9b48c11c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7405, 384)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_transformers.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21a98de7",
   "metadata": {},
   "source": [
    "##### 3. fine-tuned subword embeddings\n",
    "\n",
    "Turn sentences to vectors via word embeddings by taking the mean/sum of all word embeddings of the sentence\n",
    "\n",
    "the finetuned subword embeddings using gensim.models.fasttext of \"wiki.en.bin\" pretrained model. dimension 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f5dd1d22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7405, 300)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import retrain_word2vec,config\n",
    "\n",
    "w2v_model = retrain_word2vec.load_word2vec(config.path_w2v_models, \"nberr_subword2vec_finetune.model\")\n",
    "X_wordemb = np.array([cluster_util.vectorizer_word2vec(xi, w2v_model.wv, w2v_model.vector_size) for xi in err_descs])\n",
    "\n",
    "with open(path_res.joinpath(\"df_err_processed_pregroup_dedup_subwordembeddings.txt\"), 'wb') as f:\n",
    "    np.save(f, X_wordemb)\n",
    "    \n",
    "X_wordemb.shape # (.., 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d04b665",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is using GloVe\n",
    "# import numpy as np\n",
    "\n",
    "# glove_vectors = cluster_util.load_glove(\"C:/Users/yirwa29/Downloads/Dataset-Nb/glove.6B/glove.6B.200d.txt\")\n",
    "# X_wordemb = np.array([cluster_util.vectorizer_word2vec(xi, glove_vectors, 200) for xi in err_descs])\n",
    "\n",
    "# with open(config.path_default.joinpath(\"df_mlerr_mlbugs_filtered_dedup_embeddings_glove.txt\"), 'wb') as f:\n",
    "#     np.save(f, X_wordemb)\n",
    "    \n",
    "# X_wordemb.shape # (14518, 200)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3be22434",
   "metadata": {},
   "source": [
    "### 2. Clustering with vectorized error values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "583cff52",
   "metadata": {},
   "source": [
    "##### 2. sentence transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d8bb7e05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pca: 129 components can explain 80.04% variance of the data\n"
     ]
    }
   ],
   "source": [
    "# #PCA\n",
    "\n",
    "# import numpy as np\n",
    "\n",
    "# # with open(config.path_default.joinpath(\"df_err_processed_pregroup_dedup_embeddings_transformers.txt\"), 'rb') as f:\n",
    "# #     X_transformers = np.load(f)\n",
    "    \n",
    "# n_components = cluster_util.select_pca_n_basedon_variance(X_transformers)\n",
    "# X_transformers_pca = cluster_util.pca(X_transformers, n_components=n_components)\n",
    "\n",
    "# with open(path_res.joinpath(\"df_err_processed_pregroup_dedup_embeddings_transformers_pca.txt\"), 'wb') as f:\n",
    "#     np.save(f, X_transformers_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b9f1fe67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "with open(path_res.joinpath(\"df_err_processed_pregroup_dedup_embeddings_transformers_pca.txt\"), 'rb') as f:\n",
    "    X_transformers_pca = np.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1cc580b2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8299056807845687\n",
      "Estimated no. of clusters: 72\n",
      "Estimated no. of noise points: 637\n"
     ]
    }
   ],
   "source": [
    "## dbscan\n",
    "eps_transformers = cluster_util.epsilon_search_dbscan(X_transformers_pca)\n",
    "print(eps_transformers)\n",
    "res = cluster_util.cluster_dbscan(X_transformers_pca, eps=eps_transformers, min_samples=2)\n",
    "df_mlerr_mlbugs_unique.loc[:,\"cluster_dbscan_transformers\"] = res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7083c536",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.13126564"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster_util.eval_cluster_silhouette(X_transformers_pca[df_mlerr_mlbugs_unique['cluster_dbscan_transformers']!=-1],\n",
    "                                     df_mlerr_mlbugs_unique.loc[df_mlerr_mlbugs_unique['cluster_dbscan_transformers']!=-1, 'cluster_dbscan_transformers'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ba3ef797",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated no. of clusters: 1071\n",
      "Estimated no. of noise points: 4645\n"
     ]
    }
   ],
   "source": [
    "## OPTICS\n",
    "res = cluster_util.cluster_optics(X_transformers_pca, min_samples = 2)\n",
    "df_mlerr_mlbugs_unique.loc[:,\"cluster_optics_transformers\"] = res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a65e845d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.26892865"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster_util.eval_cluster_silhouette(X_transformers_pca[df_mlerr_mlbugs_unique['cluster_optics_transformers']!=-1],\n",
    "                                     df_mlerr_mlbugs_unique.loc[df_mlerr_mlbugs_unique['cluster_optics_transformers']!=-1, 'cluster_optics_transformers'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b8fdf5b",
   "metadata": {},
   "source": [
    "##### 3. word embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "327d50a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pca: 133 components can explain 80.05% variance of the data\n"
     ]
    }
   ],
   "source": [
    "# #PCA\n",
    "\n",
    "# import numpy as np\n",
    "\n",
    "# # with open(path_res.joinpath(\"df_mlerr_mlbugs_pregroup_dedup_subwordembeddings.txt\"), 'rb') as f:\n",
    "# #     X_wordemb = np.load(f)\n",
    "    \n",
    "# n_components = cluster_util.select_pca_n_basedon_variance(X_wordemb)\n",
    "# X_wordemb_pca = cluster_util.pca(X_wordemb, n_components=n_components)\n",
    "\n",
    "# with open(path_res.joinpath(\"df_err_processed_pregroup_dedup_subwordembeddings_pca.txt\"), 'wb') as f:\n",
    "#     np.save(f, X_wordemb_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "54c42f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "with open(path_res.joinpath(\"df_err_processed_pregroup_dedup_subwordembeddings_pca.txt\"), 'rb') as f:\n",
    "    X_wordemb_pca = np.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5652e91c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.5130986192040772\n",
      "Estimated no. of clusters: 76\n",
      "Estimated no. of noise points: 1017\n"
     ]
    }
   ],
   "source": [
    "## dbscan\n",
    "eps_wordemb = cluster_util.epsilon_search_dbscan(X_wordemb_pca)\n",
    "print(eps_wordemb)\n",
    "res = cluster_util.cluster_dbscan(X_wordemb_pca, eps=eps_wordemb, min_samples=2)\n",
    "df_mlerr_mlbugs_unique.loc[:,\"cluster_dbscan_wordemb\"] = res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2cba46a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0657767314049157"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster_util.eval_cluster_silhouette(X_wordemb_pca[df_mlerr_mlbugs_unique['cluster_dbscan_wordemb']!=-1],\n",
    "                                     df_mlerr_mlbugs_unique.loc[df_mlerr_mlbugs_unique['cluster_dbscan_wordemb']!=-1, 'cluster_dbscan_wordemb'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fc1a661d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated no. of clusters: 793\n",
      "Estimated no. of noise points: 5481\n"
     ]
    }
   ],
   "source": [
    "## OPTICS\n",
    "res = cluster_util.cluster_optics(X_wordemb_pca, min_samples = 2)\n",
    "df_mlerr_mlbugs_unique.loc[:,\"cluster_optics_wordemb\"] = res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b1df1390",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.30358481260128123"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster_util.eval_cluster_silhouette(X_wordemb_pca[df_mlerr_mlbugs_unique['cluster_optics_wordemb']!=-1],\n",
    "                                     df_mlerr_mlbugs_unique.loc[df_mlerr_mlbugs_unique['cluster_optics_wordemb']!=-1, 'cluster_optics_wordemb'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ea0561d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mlerr_mlbugs_unique.to_excel(path_res.joinpath(\"df_err_processed_pregroup_dedup_clustered.xlsx\"), index=False, engine='xlsxwriter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d0884c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b4653b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5456aa6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
