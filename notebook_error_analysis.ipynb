{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0d037800",
   "metadata": {},
   "source": [
    "## 1. Error analysis for nbs from github - the stack v1\n",
    "\n",
    "https://huggingface.co/datasets/bigcode/the-stack-dedup/tree/main/data/jupyter-notebook\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "961e2799",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in all errors from the file\n",
    "import pandas as pd\n",
    "\n",
    "df2_err = pd.read_csv('C:/Users/yirwa29/Downloads/Dataset-Nb/nberror_g_all.csv', encoding='utf-8')\n",
    "df2_err.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9c9b43a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df2_err.iloc[2]['traceback'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d770106d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2_err[df2_err[\"ename\"]=='NameError'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad5bcf03",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2_err.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73c7d96c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2_err[\"fname\"].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28fc0bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2_err[\"ename\"].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "891e508e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2_err[\"ename\"].groupby([df2_err[\"ename\"]]).count().sort_values(ascending=0)[:50].plot(kind=\"bar\", figsize=(12,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de8ecc3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2_err[\"ename\"].groupby([df2_err[\"ename\"]]).count().sort_values(ascending=0)[:10].plot(kind=\"bar\", figsize=(8,4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b278c574",
   "metadata": {},
   "source": [
    "## 2. Error analysis for nbs from kaggle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "195eef64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in all errors from the file\n",
    "import pandas as pd\n",
    "\n",
    "path_err = 'C:/Users/yirwa29/Downloads/Dataset-Nb/nbdata_k_error/nberror_k.csv'\n",
    "df_err = pd.read_csv(path_err, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d40b31a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['---------------------------------------------------------------------------', 'KeyboardInterrupt                         Traceback (most recent call last)', 'Cell In[15], line 3\\n      1 STEPS_PER_EPOCH=train_labels.shape[0] // BATCH_SIZE\\n----> 3 history= model.fit(\\n      4 train_dataset,\\n      5 epochs=EPOCHS,\\n      6 steps_per_epoch=STEPS_PER_EPOCH,\\n      7 validation_data=valid_dataset)\\n', 'File /usr/local/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:65, in filter_traceback.<locals>.error_handler(*args, **kwargs)\\n     63 filtered_tb = None\\n     64 try:\\n---> 65     return fn(*args, **kwargs)\\n     66 except Exception as e:\\n     67     filtered_tb = _process_traceback_frames(e.__traceback__)\\n', 'File /usr/local/lib/python3.10/site-packages/keras/src/engine/training.py:1783, in Model.fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\\n   1775 with tf.profiler.experimental.Trace(\\n   1776     \"train\",\\n   1777     epoch_num=epoch,\\n   (...)\\n   1780     _r=1,\\n   1781 ):\\n   1782     callbacks.on_train_batch_begin(step)\\n-> 1783     tmp_logs = self.train_function(iterator)\\n   1784     if data_handler.should_sync:\\n   1785         context.async_wait()\\n', 'File /usr/local/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150, in filter_traceback.<locals>.error_handler(*args, **kwargs)\\n    148 filtered_tb = None\\n    149 try:\\n--> 150   return fn(*args, **kwargs)\\n    151 except Exception as e:\\n    152   filtered_tb = _process_traceback_frames(e.__traceback__)\\n', 'File /usr/local/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:831, in Function.__call__(self, *args, **kwds)\\n    828 compiler = \"xla\" if self._jit_compile else \"nonXla\"\\n    830 with OptionalXlaContext(self._jit_compile):\\n--> 831   result = self._call(*args, **kwds)\\n    833 new_tracing_count = self.experimental_get_tracing_count()\\n    834 without_tracing = (tracing_count == new_tracing_count)\\n', 'File /usr/local/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:867, in Function._call(self, *args, **kwds)\\n    864   self._lock.release()\\n    865   # In this case we have created variables on the first call, so we run the\\n    866   # defunned version which is guaranteed to never create variables.\\n--> 867   return tracing_compilation.call_function(\\n    868       args, kwds, self._no_variable_creation_config\\n    869   )\\n    870 elif self._variable_creation_config is not None:\\n    871   # Release the lock early so that multiple threads can perform the call\\n    872   # in parallel.\\n    873   self._lock.release()\\n', 'File /usr/local/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139, in call_function(args, kwargs, tracing_options)\\n    137 bound_args = function.function_type.bind(*args, **kwargs)\\n    138 flat_inputs = function.function_type.unpack_inputs(bound_args)\\n--> 139 return function._call_flat(  # pylint: disable=protected-access\\n    140     flat_inputs, captured_inputs=function.captured_inputs\\n    141 )\\n', 'File /usr/local/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1264, in ConcreteFunction._call_flat(self, tensor_inputs, captured_inputs)\\n   1260 possible_gradient_type = gradients_util.PossibleTapeGradientTypes(args)\\n   1261 if (possible_gradient_type == gradients_util.POSSIBLE_GRADIENT_TYPES_NONE\\n   1262     and executing_eagerly):\\n   1263   # No tape is watching; skip to running the function.\\n-> 1264   return self._inference_function.flat_call(args)\\n   1265 forward_backward = self._select_forward_and_backward_functions(\\n   1266     args,\\n   1267     possible_gradient_type,\\n   1268     executing_eagerly)\\n   1269 forward_function, args_with_tangents = forward_backward.forward()\\n', 'File /usr/local/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:217, in AtomicFunction.flat_call(self, args)\\n    215 def flat_call(self, args: Sequence[core.Tensor]) -> Any:\\n    216   \"\"\"Calls with tensor inputs and returns the structured output.\"\"\"\\n--> 217   flat_outputs = self(*args)\\n    218   return self.function_type.pack_output(flat_outputs)\\n', 'File /usr/local/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:252, in AtomicFunction.__call__(self, *args)\\n    250 with record.stop_recording():\\n    251   if self._bound_context.executing_eagerly():\\n--> 252     outputs = self._bound_context.call_function(\\n    253         self.name,\\n    254         list(args),\\n    255         len(self.function_type.flat_outputs),\\n    256     )\\n    257   else:\\n    258     outputs = make_call_op_in_graph(\\n    259         self,\\n    260         list(args),\\n    261         self._bound_context.function_call_options.as_attrs(),\\n    262     )\\n', 'File /usr/local/lib/python3.10/site-packages/tensorflow/python/eager/context.py:1479, in Context.call_function(self, name, tensor_inputs, num_outputs)\\n   1477 cancellation_context = cancellation.context()\\n   1478 if cancellation_context is None:\\n-> 1479   outputs = execute.execute(\\n   1480       name.decode(\"utf-8\"),\\n   1481       num_outputs=num_outputs,\\n   1482       inputs=tensor_inputs,\\n   1483       attrs=attrs,\\n   1484       ctx=self,\\n   1485   )\\n   1486 else:\\n   1487   outputs = execute.execute_with_cancellation(\\n   1488       name.decode(\"utf-8\"),\\n   1489       num_outputs=num_outputs,\\n   (...)\\n   1493       cancellation_manager=cancellation_context,\\n   1494   )\\n', 'File /usr/local/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:60, in quick_execute(op_name, num_outputs, inputs, attrs, ctx, name)\\n     53   # Convert any objects of type core_types.Tensor to Tensor.\\n     54   inputs = [\\n     55       tensor_conversion_registry.convert(t)\\n     56       if isinstance(t, core_types.Tensor)\\n     57       else t\\n     58       for t in inputs\\n     59   ]\\n---> 60   tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\\n     61                                       inputs, attrs, num_outputs)\\n     62 except core._NotOkStatusException as e:\\n     63   if name is not None:\\n', 'KeyboardInterrupt: ']\n"
     ]
    }
   ],
   "source": [
    "import util\n",
    "\n",
    "res = util.parse_traceback(df_err.iloc[2]['traceback'])\n",
    "print(res)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
