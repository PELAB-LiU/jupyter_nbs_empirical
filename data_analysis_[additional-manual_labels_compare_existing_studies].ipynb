{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "23a391d9",
   "metadata": {},
   "source": [
    "# Compare to:\n",
    "## 1. An empirical study on program failures of deep learning jobs, Zhang et al, ICSE20"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d037800",
   "metadata": {},
   "source": [
    "### Label automatically notebooks that are DL\n",
    "\n",
    "based on what libraries they use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "851f4778",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "path_default=WindowsPath('C:/Users/yirwa29/Downloads/data_jupyter_nbs_empirical')\n",
      "0.4584450402144772\n",
      "0.4599447513812155\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import utils.config as config\n",
    "import utils.util as util\n",
    "import numpy as np\n",
    "\n",
    "# manually labeled and processed\n",
    "df_mlerr_labels = pd.read_excel(config.path_default.joinpath('Manual_labeing/cluster_sampled_labeled_processed.xlsx'))\n",
    "\n",
    "df_err_g = pd.read_excel(config.path_github_error_process.joinpath('nberror_g_all_eid_p.xlsx'))\n",
    "df_err_k = pd.read_excel(config.path_kaggle_error_process.joinpath('nberror_k_eid_p.xlsx'))\n",
    "\n",
    "df_err_g.drop_duplicates(subset=['eid'], keep='first', inplace = True)\n",
    "df_err_k.drop_duplicates(subset=['eid'], keep='first', inplace = True)\n",
    "\n",
    "def get_DL(df_mlerr_labels, save_path = None):\n",
    "    df_mlerr_labels = pd.merge(df_mlerr_labels, \n",
    "                               pd.concat([df_err_g[[\"eid\",\"lib_alias\"]], df_err_k[[\"eid\",\"lib_alias\"]]], ignore_index=True), \n",
    "                               on=\"eid\", how=\"left\")\n",
    "    df_mlerr_labels[\"is_DLnb\"] = df_mlerr_labels.lib_alias.apply(util.lib_alias_isDL)\n",
    "    print(sum(df_mlerr_labels[\"is_DLnb\"])/df_mlerr_labels.shape[0])\n",
    "    print(df_mlerr_labels[df_mlerr_labels.is_DLnb==True].fname.nunique()/df_mlerr_labels.fname.nunique())\n",
    "\n",
    "    df_mlerr_labels = df_mlerr_labels[df_mlerr_labels.is_DLnb==True]\n",
    "    df_mlerr_labels = df_mlerr_labels.drop(['is_DLnb', 'lib_alias'], axis=1)\n",
    "    if save_path:\n",
    "        df_mlerr_labels.to_excel(save_path, index=False, engine='xlsxwriter')\n",
    "    \n",
    "get_DL(df_mlerr_labels, save_path = config.path_default.joinpath(\"Manual_labeing/cluster_sampled_labeled_DL.xlsx\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3436975c",
   "metadata": {},
   "source": [
    "### Map our labeling to theirs: \n",
    "\n",
    "Bug type - Main categories:\n",
    "\n",
    "    Execution environment: \n",
    "        label_root_cause == config.label_root_cause[\"environment\"]\n",
    "    Data (dueing data preocessing, data integrity is compromised. i.e., corrupt data, unexpected encoding): \n",
    "        label_refined_exp_type == [\"jsondecodeerror\", \"unsupported file type (read file)\", \"incompleteparseerror\"]\n",
    "        ename==\"unicodedecodeerror\"\n",
    "    DL specific: \n",
    "        label_if_ML_bug == config.label_if_ML_bug[\"ML bug\"]\n",
    "    General code error: \n",
    "        label_if_ML_bug == config.label_if_ML_bug[\"python bug\"]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eaeeb478",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "path_default=WindowsPath('C:/Users/yirwa29/Downloads/data_jupyter_nbs_empirical')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import utils.config as config\n",
    "import numpy as np\n",
    "\n",
    "df_mlerr_labels_DL = pd.read_excel(config.path_default.joinpath('Manual_labeing/cluster_sampled_labeled_DL.xlsx'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "844039c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4584450402144772\n",
      "0.34102564102564104\n",
      "0.5870786516853933\n"
     ]
    }
   ],
   "source": [
    "print(df_mlerr_labels_DL.shape[0]/(390+356))\n",
    "print(df_mlerr_labels_DL[df_mlerr_labels_DL.nb_source==2].shape[0]/390) # GH\n",
    "print(df_mlerr_labels_DL[df_mlerr_labels_DL.nb_source==1].shape[0]/356) # Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a30886d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mlerr_labels_DL[\"Comp1_DLJobs\"] = -1\n",
    "df_mlerr_labels_DL[\"Comp1_DLJobs\"] = np.where(df_mlerr_labels_DL['label_root_cause'].isin(config.label_root_cause[\"environment setting\"]),\n",
    "                                              \"Execution environment\",\n",
    "                                              df_mlerr_labels_DL[\"Comp1_DLJobs\"])\n",
    "df_mlerr_labels_DL[\"Comp1_DLJobs\"] = np.where((df_mlerr_labels_DL['label_refined_exp_type'].isin([\"jsondecodeerror\", \"unsupported file type (read file)\", \"incompleteparseerror\"])|(df_mlerr_labels_DL['ename']==\"unicodedecodeerror\"))&(df_mlerr_labels_DL[\"Comp1_DLJobs\"]==\"-1\"),\n",
    "                                              \"Data\",\n",
    "                                              df_mlerr_labels_DL[\"Comp1_DLJobs\"])\n",
    "df_mlerr_labels_DL[\"Comp1_DLJobs\"] = np.where(df_mlerr_labels_DL['label_if_ML_bug'].isin(config.label_if_ML_bug[\"ML bug\"])&(df_mlerr_labels_DL[\"Comp1_DLJobs\"]==\"-1\"),\n",
    "                                              \"DL specific\",\n",
    "                                              df_mlerr_labels_DL[\"Comp1_DLJobs\"])\n",
    "df_mlerr_labels_DL[\"Comp1_DLJobs\"] = np.where(df_mlerr_labels_DL['label_if_ML_bug'].isin(config.label_if_ML_bug[\"python bug\"])&(df_mlerr_labels_DL[\"Comp1_DLJobs\"]==\"-1\"),\n",
    "                                              \"General code error\",\n",
    "                                              df_mlerr_labels_DL[\"Comp1_DLJobs\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a6d04af1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Comp1_DLJobs\n",
       "DL specific              205\n",
       "Execution environment     68\n",
       "General code error        66\n",
       "Data                       3\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_mlerr_labels_DL[\"Comp1_DLJobs\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "572ddbc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Comp1_DLJobs\n",
       "DL specific              0.599415\n",
       "Execution environment    0.198830\n",
       "General code error       0.192982\n",
       "Data                     0.008772\n",
       "Name: count, dtype: float64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_mlerr_labels_DL[\"Comp1_DLJobs\"].value_counts()/df_mlerr_labels_DL.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42eba583",
   "metadata": {},
   "source": [
    "Bug type - Sub-categories:\n",
    "\n",
    "DL specific:\n",
    "\n",
    "    GPU out of memory/CPU out of memory:\n",
    "        label_refined_exp_type==\"out of memory (OOM)\"\n",
    "    Framework API misuse:\n",
    "        label_root_cause.isin(config.label_root_cause[\"API\"])\n",
    "    Tensor Mismatch:\n",
    "        label_refined_exp_type==\"tensor shape mismatch\"\n",
    "    Loss NaN: - \n",
    "    \n",
    "    ++ what is the top 3 for us?\n",
    "    \n",
    "Execution environment:\n",
    "\n",
    "    Path not found:\n",
    "        label_root_cause==\"file/path not found or exist\"\n",
    "    Library not found:\n",
    "        label_root_cause==\"module not installed\"\n",
    "    Permission denied:\n",
    "        label_root_cause==\"settings(permission, environment)\"\n",
    "    \n",
    "    ++ what is the top 1 for us?\n",
    "    \n",
    "General code error:\n",
    "\n",
    "    Illegal argument:\n",
    "        label_root_cause.isin(config.label_root_cause[\"API\"])\n",
    "    Type mismatch:\n",
    "        label_refined_exp_type.isin(config.label_refined_exp_type[\"type\"])\n",
    "    Key not found:\n",
    "        label_refined_exp_type.isin(config.label_refined_exp_type[\"key\"])\n",
    "    ...\n",
    "    \n",
    "    ++ what is the top 3 for us?\n",
    "    \n",
    "Data:\n",
    "\n",
    "    Corrupt data:\n",
    "        label_refined_exp_type == [\"unsupported file type (read file)\", \"incompleteparseerror\"]\n",
    "    Unexpected encoding:\n",
    "        label_refined_exp_type == \"jsondecodeerror\" | ename==\"unicodedecodeerror\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1acb9696",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU/CPU out of memory:  0.07804878048780488 0.04678362573099415\n",
      "Tensor Mismatch:  0.14634146341463414 0.08771929824561403\n",
      "Framework API misuse:  0.21951219512195122 0.13157894736842105\n",
      "Other:  0.5560975609756098 0.3333333333333333\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "label_refined_exp_type\n",
       "tensor shape mismatch                                 30\n",
       "variable not found                                    29\n",
       "wrong arguments to API                                26\n",
       "out of memory (OOM)                                   16\n",
       "attributeerror                                        12\n",
       "module not found                                      12\n",
       "keyerror                                              10\n",
       "valueerror - data value violation                      9\n",
       "runtimeerror                                           8\n",
       "unsupported broadcast                                  5\n",
       "cast exception                                         5\n",
       "valueerror - data range mismatch                       5\n",
       "indexerror-nd                                          5\n",
       "valueerror - feature name mismatch                     4\n",
       "function not found                                     4\n",
       "indexerror-1d                                          4\n",
       "typeerror-notcallable                                  3\n",
       "typeerror-notsubscriptable                             3\n",
       "typeerror                                              3\n",
       "initialization error (call mul-times, wrong order)     2\n",
       "typeerror-notiterable                                  2\n",
       "nameerror                                              1\n",
       "notfounderror                                          1\n",
       "filenotfounderror                                      1\n",
       "indentationerror                                       1\n",
       "importerror                                            1\n",
       "out of space (disk)                                    1\n",
       "typeerror-unhashable                                   1\n",
       "unknown                                                1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_mlerr_labels_DL_dlspecific = df_mlerr_labels_DL[df_mlerr_labels_DL[\"Comp1_DLJobs\"]==\"DL specific\"]\n",
    "n_oom = sum(df_mlerr_labels_DL_dlspecific[\"label_refined_exp_type\"]==\"out of memory (OOM)\")\n",
    "n_tm = sum(df_mlerr_labels_DL_dlspecific[\"label_refined_exp_type\"]==\"tensor shape mismatch\")\n",
    "n_api = sum(df_mlerr_labels_DL_dlspecific[\"label_root_cause\"].isin(config.label_root_cause[\"API misuse\"])&(df_mlerr_labels_DL_dlspecific[\"label_refined_exp_type\"]!=\"tensor shape mismatch\"))\n",
    "\n",
    "print(\"GPU/CPU out of memory: \", n_oom/df_mlerr_labels_DL_dlspecific.shape[0], n_oom/df_mlerr_labels_DL.shape[0])\n",
    "print(\"Tensor Mismatch: \", n_tm/df_mlerr_labels_DL_dlspecific.shape[0], n_tm/df_mlerr_labels_DL.shape[0])\n",
    "print(\"Framework API misuse: \", n_api/df_mlerr_labels_DL_dlspecific.shape[0], n_api/df_mlerr_labels_DL.shape[0])\n",
    "\n",
    "print(\"Other: \", 1-(n_oom+n_tm+n_api)/df_mlerr_labels_DL_dlspecific.shape[0], (df_mlerr_labels_DL_dlspecific.shape[0]-(n_oom+n_tm+n_api))/df_mlerr_labels_DL.shape[0])\n",
    "\n",
    "df_mlerr_labels_DL_dlspecific.label_refined_exp_type.value_counts()\n",
    "# our top 3 are the same as theirs (tho we label API misuse a bit differently - as root cause)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "453f69ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path not found:  0.5147058823529411 0.1023391812865497\n",
      "Library not found:  0.16176470588235295 0.03216374269005848\n",
      "Permission denied:  0.14705882352941177 0.029239766081871343\n",
      "Other:  0.17647058823529416 0.03508771929824561\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "label_root_cause\n",
       "file/path not found or exist         35\n",
       "module not installed                 11\n",
       "settings(permission, environment)    10\n",
       "library versions incompatible         7\n",
       "change of environment                 3\n",
       "external control (window closed)      2\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_mlerr_labels_DL_env = df_mlerr_labels_DL[df_mlerr_labels_DL[\"Comp1_DLJobs\"]==\"Execution environment\"]\n",
    "n_pnf = sum((df_mlerr_labels_DL_env[\"label_root_cause\"]==\"file/path not found or exist\"))\n",
    "n_lnf = sum(df_mlerr_labels_DL_env[\"label_root_cause\"]==\"module not installed\")\n",
    "n_pd = sum(df_mlerr_labels_DL_env[\"label_root_cause\"]==\"settings(permission, environment)\")\n",
    "\n",
    "print(\"Path not found: \", n_pnf/df_mlerr_labels_DL_env.shape[0], n_pnf/df_mlerr_labels_DL.shape[0])\n",
    "print(\"Library not found: \", n_lnf/df_mlerr_labels_DL_env.shape[0], n_lnf/df_mlerr_labels_DL.shape[0])\n",
    "print(\"Permission denied: \", n_pd/df_mlerr_labels_DL_env.shape[0], n_pd/df_mlerr_labels_DL.shape[0])\n",
    "\n",
    "print(\"Other: \", 1-(n_pnf+n_lnf+n_pd)/df_mlerr_labels_DL_env.shape[0], (df_mlerr_labels_DL_env.shape[0]-(n_pnf+n_lnf+n_pd))/df_mlerr_labels_DL.shape[0])\n",
    "\n",
    "df_mlerr_labels_DL_env.label_root_cause.value_counts()\n",
    "# top 3 align"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7cd0e663",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Illegal argument:  0.18181818181818182 0.03508771929824561\n",
      "Type mismatch:  0.06060606060606061 0.011695906432748537\n",
      "Key not found:  0.0 0.0\n",
      "The rest:  0.4090909090909091 0.07894736842105263\n",
      "Other:  0.3484848484848485 0.06725146198830409\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "label_refined_exp_type\n",
       "variable not found                  17\n",
       "function not found                  11\n",
       "attributeerror                       6\n",
       "module not found                     5\n",
       "wrong arguments to API               5\n",
       "indexerror-1d                        3\n",
       "valueerror - data range mismatch     3\n",
       "class not found                      2\n",
       "typeerror                            2\n",
       "syntaxerror                          2\n",
       "keyerror                             1\n",
       "requesterror                         1\n",
       "typeerror-notiterable                1\n",
       "systemerror                          1\n",
       "valueerror                           1\n",
       "filenotfounderror                    1\n",
       "typeerror-op                         1\n",
       "indexerror-nd                        1\n",
       "typeerror-notcallable                1\n",
       "typeerror-notsubscriptable           1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_mlerr_labels_DL_py = df_mlerr_labels_DL[df_mlerr_labels_DL[\"Comp1_DLJobs\"]==\"General code error\"]\n",
    "n_arg = sum((df_mlerr_labels_DL_py[\"label_root_cause\"].isin(config.label_root_cause[\"API misuse\"])))\n",
    "n_type = sum((~df_mlerr_labels_DL_py[\"label_root_cause\"].isin(config.label_root_cause[\"API misuse\"]))&\n",
    "             (df_mlerr_labels_DL_py[\"label_refined_exp_type\"].isin(config.label_refined_exp_type[\"type error\"])))\n",
    "n_key = sum((~df_mlerr_labels_DL_py[\"label_root_cause\"].isin(config.label_root_cause[\"API misuse\"]))&\n",
    "            (df_mlerr_labels_DL_py[\"label_refined_exp_type\"].isin(config.label_refined_exp_type[\"key error\"])))\n",
    "n_rest = sum((~df_mlerr_labels_DL_py[\"label_root_cause\"].isin(config.label_root_cause[\"API misuse\"]))&\n",
    "             (df_mlerr_labels_DL_py[\"label_refined_exp_type\"].isin([\"function not found\", \"syntaxerror\", \"zerodivisionerror\"]+\n",
    "                                                                    config.label_refined_exp_type[\"variable not found\"]+\n",
    "                                                                    config.label_refined_exp_type[\"attribute error\"]+\n",
    "                                                                    config.label_refined_exp_type[\"index error\"])))\n",
    "print(\"Illegal argument: \", n_arg/df_mlerr_labels_DL_py.shape[0], n_arg/df_mlerr_labels_DL.shape[0])\n",
    "print(\"Type mismatch: \", n_type/df_mlerr_labels_DL_py.shape[0], n_type/df_mlerr_labels_DL.shape[0])\n",
    "print(\"Key not found: \", n_key/df_mlerr_labels_DL_py.shape[0], n_key/df_mlerr_labels_DL.shape[0])\n",
    "print(\"The rest: \", n_rest/df_mlerr_labels_DL_py.shape[0], n_rest/df_mlerr_labels_DL.shape[0])\n",
    "\n",
    "print(\"Other: \", 1-(n_arg+n_type+n_key+n_rest)/df_mlerr_labels_DL_py.shape[0], (df_mlerr_labels_DL_py.shape[0]-(n_arg+n_type+n_key+n_rest))/df_mlerr_labels_DL.shape[0])\n",
    "\n",
    "df_mlerr_labels_DL_py.label_refined_exp_type.value_counts()\n",
    "# name error is the most, then illegal argument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "90cd5817",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corrupt data:  1.0 0.008771929824561403\n",
      "Unexpected encoding:  0.0 0.0\n",
      "Other:  0.0 0.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "label_refined_exp_type\n",
       "unsupported file type (read file)    3\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_mlerr_labels_DL_data = df_mlerr_labels_DL[df_mlerr_labels_DL[\"Comp1_DLJobs\"]==\"Data\"]\n",
    "n_cd = sum((df_mlerr_labels_DL_data[\"label_refined_exp_type\"].isin([\"unsupported file type (read file)\", \"incompleteparseerror\"])))\n",
    "n_en = sum((df_mlerr_labels_DL_data[\"label_refined_exp_type\"]==\"jsondecodeerror\")|(df_mlerr_labels_DL_data[\"ename\"]==\"unicodedecodeerror\"))\n",
    "\n",
    "print(\"Corrupt data: \", n_cd/df_mlerr_labels_DL_data.shape[0], n_cd/df_mlerr_labels_DL.shape[0])\n",
    "print(\"Unexpected encoding: \", n_en/df_mlerr_labels_DL_data.shape[0], n_en/df_mlerr_labels_DL.shape[0])\n",
    "\n",
    "print(\"Other: \", 1-(n_cd+n_en)/df_mlerr_labels_DL_data.shape[0], (df_mlerr_labels_DL_data.shape[0]-(n_cd+n_en))/df_mlerr_labels_DL.shape[0])\n",
    "\n",
    "df_mlerr_labels_DL_data.label_refined_exp_type.value_counts()\n",
    "# all three cases are corrupted data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0babdc4",
   "metadata": {},
   "source": [
    "ML pipeline stages:\n",
    "\n",
    "    Initialization (30.8):\n",
    "        label_ML_pipeline: config.label_ML_pipeline[\"environment setup\"]\n",
    "    Data preprocessing (30):\n",
    "        label_ML_pipeline: config.label_ML_pipeline[\"data preparation\"], config.label_ML_pipeline[\"data visualization\"]\n",
    "    Training&validation (15):\n",
    "        label_ML_pipeline: config.label_ML_pipeline[\"model construction\"], config.label_ML_pipeline[\"training\"]\n",
    "    Model evaluation (24.3):\n",
    "        label_ML_pipeline: config.label_ML_pipeline[\"evaluation/prediction\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "54738c59",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialization:  0.07602339181286549\n",
      "Data preprocessing:  0.24853801169590642\n",
      "Training&validation:  0.43567251461988304\n",
      "Model evaluation:  0.23976608187134502\n"
     ]
    }
   ],
   "source": [
    "print(\"Initialization: \", sum((df_mlerr_labels_DL[\"label_ML_pipeline\"].isin(config.label_ML_pipeline[\"environment setup\"])))/df_mlerr_labels_DL.shape[0])\n",
    "print(\"Data preprocessing: \", sum((df_mlerr_labels_DL[\"label_ML_pipeline\"].isin(config.label_ML_pipeline[\"data preparation\"]+config.label_ML_pipeline[\"data visualization\"])))/df_mlerr_labels_DL.shape[0])\n",
    "print(\"Training&validation: \", sum((df_mlerr_labels_DL[\"label_ML_pipeline\"].isin(config.label_ML_pipeline[\"model construction\"]+config.label_ML_pipeline[\"training\"])))/df_mlerr_labels_DL.shape[0])\n",
    "print(\"Model evaluation: \", sum((df_mlerr_labels_DL[\"label_ML_pipeline\"].isin(config.label_ML_pipeline[\"evaluation/prediction\"])))/df_mlerr_labels_DL.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f1ee350",
   "metadata": {},
   "source": [
    "## 2. Bug Analysis in Jupyter Notebook Projects: An Empirical Study, De Santana et al, TSEM2024"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d145968",
   "metadata": {},
   "source": [
    "### Map our labeling to theirs: \n",
    "\n",
    "Bug type - Main categories:\n",
    "\n",
    "    Kernel: -\n",
    "    Conversion: -\n",
    "    Portability: -\n",
    "    Environment and settings (missing libraries, incompatible libraries..) (SO 43%, GH 36%):\n",
    "        label_root_cause.isin([\"module not installed\", \"library versions incompatible\"])\n",
    "        we also have: \n",
    "            change of environment, \n",
    "            file/path not found or exist, \n",
    "            settings(permission, environment), \n",
    "            external control (window closed)\n",
    "    Connection: -\n",
    "    Processing (5%, 2%):\n",
    "        label_root_cause.isin(config.label_root_cause[\"resources\"])\n",
    "    Cell defect: -\n",
    "    Implementation (22%, 44%):\n",
    "        Semantic Error (not crashes): -\n",
    "        Syntax Error: -\n",
    "        Data Science lib wrong usage:\n",
    "            label_root_cause.isin(config.label_root_cause[\"API\"])&label_if_ML_bug.isin(config.label_if_ML_bug[\"ML bug\"])\n",
    "        Data Science Algorithm Error: \n",
    "            label_root_cause.isin(config.label_root_cause[\"implementation\"])&label_if_ML_bug.isin(config.label_if_ML_bug[\"ML bug\"])\n",
    "     we also have: NB specific, data, library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "906ba69f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import utils.config as config\n",
    "import numpy as np\n",
    "\n",
    "# manually labeled and processed\n",
    "df_mlerr_labels = pd.read_excel(config.path_default.joinpath('Manual_labeing/cluster_sampled_labeled_processed.xlsx'))\n",
    "df_mlerr_labels_sum = pd.read_excel(config.path_default.joinpath('Manual_labeing/cluster_sampled_labeled_sum.xlsx'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c8a6c8d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment and settings:  0.05227882037533512\n",
      "Processing:  0.022788203753351208\n",
      "Implementation:  0.24396782841823056\n",
      "    Implementation - Data Science lib wrong usage:  0.1675603217158177\n",
      "    Implementation - Data Science Algorithm Error:  0.07640750670241286\n"
     ]
    }
   ],
   "source": [
    "print(\"Environment and settings: \", \n",
    "      sum((df_mlerr_labels[\"label_root_cause\"].isin([\"module not installed\", \"library versions incompatible\"])))/df_mlerr_labels.shape[0])\n",
    "print(\"Processing: \", \n",
    "      sum((df_mlerr_labels[\"label_root_cause\"].isin(config.label_root_cause[\"insufficient resource\"])))/df_mlerr_labels.shape[0])\n",
    "\n",
    "n_impl_api = sum((df_mlerr_labels[\"label_root_cause\"].isin(config.label_root_cause[\"API misuse\"])&df_mlerr_labels[\"label_if_ML_bug\"].isin(config.label_if_ML_bug[\"ML bug\"])))\n",
    "n_impl_impl = sum((df_mlerr_labels[\"label_root_cause\"].isin(config.label_root_cause[\"implementation error\"])&df_mlerr_labels[\"label_if_ML_bug\"].isin(config.label_if_ML_bug[\"ML bug\"])))\n",
    "print(\"Implementation: \", (n_impl_api + n_impl_impl)/df_mlerr_labels.shape[0])\n",
    "print(\"    Implementation - Data Science lib wrong usage: \", n_impl_api/df_mlerr_labels.shape[0])\n",
    "print(\"    Implementation - Data Science Algorithm Error: \", n_impl_impl/df_mlerr_labels.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "404ad4ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label_root_cause\n",
       "API misuse               0.209115\n",
       "NB specific              0.194370\n",
       "implementation error     0.167560\n",
       "environment setting      0.167560\n",
       "data confusion           0.164879\n",
       "unknown                  0.038874\n",
       "insufficient resource    0.022788\n",
       "ML model confusion       0.022788\n",
       "library cause            0.012064\n",
       "Name: count, dtype: float64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_mlerr_labels_sum[\"label_root_cause\"].value_counts()/df_mlerr_labels_sum.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a81c6fd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6809999999999999"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# other implementation:\n",
    "1-0.052-0.023-0.244"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
