{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0d037800",
   "metadata": {},
   "source": [
    "# Notebook error process \n",
    "\n",
    "### filter out error notebooks with uninteresting exception types and error notebooks not using any of the top ML libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7518de1",
   "metadata": {},
   "source": [
    "### 1 mark only the ones using the selected libraries -> is_MLnb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b09c90f0",
   "metadata": {},
   "source": [
    "\n",
    "### 1.1 nbs from github"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "08c5a4b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "path_default=WindowsPath('C:/Users/yirwa29/Downloads/Dataset-Nb')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import util\n",
    "import config\n",
    "\n",
    "df2_err = pd.read_excel(config.path_github_error_process.joinpath('nberror_g_all_eid_p.xlsx'))\n",
    "df2_err[\"is_MLnb\"] = df2_err.lib_alias.apply(util.lib_alias_isML)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f505e9a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80.48% of all the python GitHub notebooks(containing errors) use the selected ML libraries\n"
     ]
    }
   ],
   "source": [
    "print(\"{0:.2%} of all the python GitHub notebooks(containing errors) use the selected ML libraries\".format(sum(df2_err[[\"fname\",\"is_MLnb\"]].drop_duplicates().is_MLnb)/df2_err.fname.nunique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dbf472f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2_err.to_excel(config.path_github_error_process.joinpath('nberror_g_all_eid_p.xlsx'), index=False, engine=\"xlsxwriter\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b549953d",
   "metadata": {},
   "source": [
    "### 1.2 nbs from kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ec9c1c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import util\n",
    "import config\n",
    "\n",
    "df_err = pd.read_excel(config.path_kaggle_error_process.joinpath('nberror_k_eid_p.xlsx'))\n",
    "df_err[\"is_MLnb\"] = df_err.lib_alias.apply(util.lib_alias_isML)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2c782c67",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 93.45% of all error Kaggle notebooks using the selected ML libraries\n"
     ]
    }
   ],
   "source": [
    "print(\"There are {0:.2%} of all error Kaggle notebooks using the selected ML libraries\".format(sum(df_err[[\"fname\",\"is_MLnb\"]].drop_duplicates().is_MLnb)/df_err.fname.nunique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "581352d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_err.to_excel(config.path_kaggle_error_process.joinpath('nberror_k_eid_p.xlsx'), index=False, engine=\"xlsxwriter\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88426529",
   "metadata": {},
   "source": [
    "### 2 mark the ones with uninteresting exception types -> is_relevant\n",
    "\n",
    "### Pending--> 2.1 First, let us gather all the exception types appeared in both error dataset and select a list of uninteresting ones:\n",
    "\n",
    "    https://liuonline-my.sharepoint.com/:x:/r/personal/yirwa29_liu_se/_layouts/15/Doc.aspx?sourcedoc=%7B55EB4974-57AF-46DF-A27E-83FEBAB67B69%7D&file=nberror_exception_types.xlsx&action=default&mobileredirect=true\n",
    "\n",
    "    Write to **config.builtin_exps_excluded** when selected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a08ef1c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import util\n",
    "import config\n",
    "\n",
    "df2_err = pd.read_excel(config.path_github_error_process.joinpath('nberror_g_all_eid_p.xlsx'))\n",
    "df_err = pd.read_excel(config.path_kaggle_error_process.joinpath('nberror_k_eid_p.xlsx'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e1f1a80e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_tmp1 = df_err[[\"ename\", \"ename_mapped\"]].drop_duplicates().sort_values(by=['ename_mapped'])\n",
    "# df_tmp2 = df2_err[[\"ename\", \"ename_mapped\"]].drop_duplicates().sort_values(by=['ename_mapped'])\n",
    "# df_tmp3 = pd.merge(df_tmp1, df_tmp2, on=\"ename\", how=\"outer\")\n",
    "# df_tmp3['ename_mapped'] = df_tmp3['ename_mapped_x'].fillna(df_tmp3['ename_mapped_y'])\n",
    "# df_tmp3 = df_tmp3[[\"ename\", \"ename_mapped\"]]\n",
    "# df_tmp3.to_excel(config.path_default + '/nberror_exception_types.xlsx', index=False, engine=\"xlsxwriter\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b278c574",
   "metadata": {},
   "source": [
    "### 2.2 Mark if relevant interms of exceptions for nbs from kaggle and github\n",
    "\n",
    "#### ----> we now only exclude \"keyboardinterrupt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "05bcbe54",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_err[\"is_relevant\"] = ~df_err.ename_mapped.isin(config.builtin_exps_excluded)\n",
    "df2_err[\"is_relevant\"] = ~df2_err.ename_mapped.isin(config.builtin_exps_excluded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ec91fe77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 83.28% of all errors in Kaggle notebooks have relevant exception types\n",
      "There are 89.41% of all errors in GitHub notebooks have relevant exception types\n"
     ]
    }
   ],
   "source": [
    "print(\"There are {0:.2%} of all errors in Kaggle notebooks have relevant exception types\".format(sum(df_err.is_relevant)/len(df_err)))\n",
    "print(\"There are {0:.2%} of all errors in GitHub notebooks have relevant exception types\".format(sum(df2_err.is_relevant)/len(df2_err)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "50b29a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_err.to_excel(config.path_kaggle_error_process.joinpath('nberror_k_eid_p.xlsx'), index=False, engine=\"xlsxwriter\")\n",
    "df2_err.to_excel(config.path_github_error_process.joinpath('nberror_g_all_eid_p.xlsx'), index=False, engine=\"xlsxwriter\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ededa827",
   "metadata": {},
   "source": [
    "### 3 Statistics if filtering out all the errors that are not from ML notebooks and all errors that are not relevant exceptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d33e1bdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "path_default=WindowsPath('C:/Users/yirwa29/Downloads/Dataset-Nb')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import util\n",
    "import config\n",
    "\n",
    "df2_err = pd.read_excel(config.path_github_error_process.joinpath('nberror_g_all_eid_p.xlsx'))\n",
    "df_err = pd.read_excel(config.path_kaggle_error_process.joinpath('nberror_k_eid_p.xlsx'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2d944edf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91.53%(6202) of all errors(6776),93.45%(4064) of all notebooks(4349), in Kaggle notebooks use the selected ML libraries\n",
      "83.28%(5643) of all errors(6776),82.62%(3593) of all notebooks(4349), in Kaggle notebooks have relevant exception types\n",
      "77.11%(5225) of all errors(6776),82.18%(3574) of all notebooks(4349), in Kaggle notebooks can be parsed into AST\n",
      "57.87%(3921) of all errors(6776),62.22%(2706) of all notebooks(4349), in Kaggle notebooks remain, after all the filtering above.\n",
      "\n",
      "\n",
      "77.89%(138075) of all errors(177258),80.48%(87665) of all notebooks(108925), in GitHub notebooks use the selected ML libraries\n",
      "89.41%(158489) of all errors(177258),88.25%(96123) of all notebooks(108925), in GitHub notebooks have relevant exception types\n",
      "82.09%(145516) of all errors(177258),87.16%(94939) of all notebooks(108925), in GitHub notebooks can be parsed into AST\n",
      "57.28%(101532) of all errors(177258),61.30%(66771) of all notebooks(108925), in GitHub notebooks remain, after all the filtering above.\n",
      "\n",
      "\n",
      "If only consider notebooks with python version 3\n",
      "\n",
      "91.52%(6194) of all errors(6768),93.44%(4059) of all notebooks(4344), in Kaggle notebooks use the selected ML libraries\n",
      "83.29%(5637) of all errors(6768),82.62%(3589) of all notebooks(4344), in Kaggle notebooks have relevant exception types\n",
      "77.08%(5217) of all errors(6768),82.16%(3569) of all notebooks(4344), in Kaggle notebooks can be parsed into AST\n",
      "57.85%(3915) of all errors(6768),62.20%(2702) of all notebooks(4344), in Kaggle notebooks remain, after all the filtering above.\n",
      "\n",
      "\n",
      "77.18%(117065) of all errors(151684),79.88%(73819) of all notebooks(92416), in GitHub notebooks use the selected ML libraries\n",
      "89.84%(136271) of all errors(151684),88.47%(81759) of all notebooks(92416), in GitHub notebooks have relevant exception types\n",
      "81.87%(124191) of all errors(151684),86.91%(80322) of all notebooks(92416), in GitHub notebooks can be parsed into AST\n",
      "57.01%(86477) of all errors(151684),60.87%(56249) of all notebooks(92416), in GitHub notebooks remain, after all the filtering above.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def print_statistics(df_tar_all, category=\"Kaggle\", if_py3=True):\n",
    "    if if_py3:\n",
    "        df_tar = df_tar_all[df_tar_all.python_version==3]\n",
    "    else:\n",
    "        df_tar = df_tar_all\n",
    "    print(\"{:.2%}({}) of all errors({}),{:.2%}({}) of all notebooks({}), in {} notebooks use the selected ML libraries\".format(\n",
    "        len(df_tar[df_tar.is_MLnb])/len(df_tar),\n",
    "        len(df_tar[df_tar.is_MLnb]),\n",
    "        len(df_tar),\n",
    "        df_tar[df_tar.is_MLnb].fname.nunique()/df_tar.fname.nunique(),\n",
    "        df_tar[df_tar.is_MLnb].fname.nunique(),\n",
    "        df_tar.fname.nunique(),\n",
    "        category))\n",
    "    print(\"{:.2%}({}) of all errors({}),{:.2%}({}) of all notebooks({}), in {} notebooks have relevant exception types\".format(\n",
    "        len(df_tar[df_tar.is_relevant])/len(df_tar),\n",
    "        len(df_tar[df_tar.is_relevant]),\n",
    "        len(df_tar),\n",
    "        df_tar[df_tar.is_relevant].fname.nunique()/df_tar.fname.nunique(),\n",
    "        df_tar[df_tar.is_relevant].fname.nunique(), \n",
    "        df_tar.fname.nunique(),\n",
    "        category))\n",
    "    print(\"{:.2%}({}) of all errors({}),{:.2%}({}) of all notebooks({}), in {} notebooks can be parsed into AST\".format(\n",
    "        len(df_tar[df_tar.if_ast==1.0])/len(df_tar),\n",
    "        len(df_tar[df_tar.if_ast==1.0]),\n",
    "        len(df_tar),\n",
    "        df_tar[df_tar.if_ast==1.0].fname.nunique()/df_tar.fname.nunique(),\n",
    "        df_tar[df_tar.if_ast==1.0].fname.nunique(), \n",
    "        df_tar.fname.nunique(),\n",
    "        category))\n",
    "    df_tar_filtered = df_tar[df_tar.is_MLnb&df_tar.is_relevant&df_tar.if_ast==1.0]\n",
    "    print(\"{:.2%}({}) of all errors({}),{:.2%}({}) of all notebooks({}), in {} notebooks remain, after all the filtering above.\".format(\n",
    "        len(df_tar_filtered)/len(df_tar), \n",
    "        len(df_tar_filtered), \n",
    "        len(df_tar),\n",
    "        df_tar_filtered.fname.nunique()/df_tar.fname.nunique(),\n",
    "        df_tar_filtered.fname.nunique(),\n",
    "        df_tar.fname.nunique(),\n",
    "        category))\n",
    "    print(\"\\n\")\n",
    "\n",
    "print_statistics(df_err, category=\"Kaggle\", if_py3=False)\n",
    "print_statistics(df2_err, category=\"GitHub\", if_py3=False)\n",
    "print(\"If only consider notebooks with python version 3\\n\")\n",
    "print_statistics(df_err, category=\"Kaggle\")\n",
    "print_statistics(df2_err, category=\"GitHub\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "00c39679",
   "metadata": {},
   "outputs": [],
   "source": [
    "# can be presented in stacked chart, \n",
    "# e.g., is_relevant (is_ML, ~is_ML), ~is_relevant (is_ML, ~is_ML)\n",
    "# e.g., is_ast (is_ML, ~is_ML), ~is_ast(is_ML, ~is_ML)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
