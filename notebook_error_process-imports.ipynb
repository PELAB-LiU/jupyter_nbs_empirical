{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0d037800",
   "metadata": {},
   "source": [
    "# Notebook error process "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c208a35",
   "metadata": {},
   "source": [
    "### Extract imported libraries and their alias used in the error notebook dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b09c90f0",
   "metadata": {},
   "source": [
    "\n",
    "### 1. nbs from github"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "85523275",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "path_default=WindowsPath('C:/Users/yirwa29/Downloads/Dataset-Nb')\n",
      "Unexpected error converting to json 00158-905-0706-afternoon.ipynb\n",
      "Unexpected error converting to json 00256-222-pclab-nlp.ipynb\n",
      "Unexpected error converting to json 00274-1884-data-wrangling-json.ipynb\n",
      "Unexpected error converting to json 00279-3344-datasets.ipynb\n",
      "Unexpected error converting to json 00286-2647-ch01.ipynb\n",
      "Successfully parsed 112425/112430 notebook files, failed 5 ones.\n"
     ]
    }
   ],
   "source": [
    "# extract all imports from all error nbs (all langauges)\n",
    "import imports_parser\n",
    "import config\n",
    "import pandas as pd\n",
    "\n",
    "res = imports_parser.get_imports_nbs_static(config.path_github_error_process.joinpath(\"nbs\"), imports_parser.get_imports_line_all)\n",
    "res_pd = pd.DataFrame.from_dict(res)\n",
    "res_pd[\"lib_alias\"] = res_pd.imports.apply(imports_parser.get_lib_alias)\n",
    "res_pd.to_excel(config.path_github_error_process.joinpath(\"imports_all_info.xlsx\"), index=False, engine=\"xlsxwriter\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e03c7f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import util\n",
    "import config\n",
    "\n",
    "df_imports = pd.read_excel(config.path_github_error_process.joinpath(\"imports_all_info.xlsx\"))\n",
    "df2_err = pd.read_excel(config.path_github_error_process.joinpath(\"nberror_g_all_eid_p.xlsx\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a5ca9ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2_err = pd.merge(df2_err, df_imports, on=\"fname\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "05a4e078",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2_err.to_excel(config.path_github_error_process.joinpath(\"nberror_g_all_eid_p.xlsx\"), index=False, engine='xlsxwriter')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b278c574",
   "metadata": {},
   "source": [
    "### 2. nbs from kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c3e4b674",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully parsed 4349/4349 notebook files, failed 0 ones.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fname</th>\n",
       "      <th>imports</th>\n",
       "      <th>lib_alias</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aadyac_ingenium-level3.ipynb</td>\n",
       "      <td>{(, seaborn, sns), (, cv2, ), (, matplotlib.py...</td>\n",
       "      <td>[[seaborn, sns], [cv2, cv2], [matplotlib, plt]...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>abaojiang_eda-on-game-progress.ipynb</td>\n",
       "      <td>{(, seaborn, sns), (typing, Any, ), (typing, U...</td>\n",
       "      <td>[[seaborn, sns], [typing, Any], [typing, Union...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>abdallahelsayed22_image-segmentation-u-net.ipynb</td>\n",
       "      <td>{(keras.layers, Conv2D, ), (tensorflow.keras.u...</td>\n",
       "      <td>[[keras, Conv2D], [tensorflow, normalize], [ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>abdallahwagih_plant-stress-identification-acc-...</td>\n",
       "      <td>{(tensorflow.keras.layers, Activation, ), (, w...</td>\n",
       "      <td>[[tensorflow, Activation], [warnings, warnings...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>abdelrahmanmuhsen_semseg-tests.ipynb</td>\n",
       "      <td>{(, tensorflow, tf), (keras.layers, Conv2D, ),...</td>\n",
       "      <td>[[tensorflow, tf], [keras, Conv2D], [tqdm, tqd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4344</th>\n",
       "      <td>yeohhanyi_cirrhosis-outcomes.ipynb</td>\n",
       "      <td>{(, tensorflow, tf), (sklearn.preprocessing, S...</td>\n",
       "      <td>[[tensorflow, tf], [sklearn, StandardScaler], ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4345</th>\n",
       "      <td>yeohqiwei_credit-card-fraud-transaction-classi...</td>\n",
       "      <td>{(sklearn.utils.class_weight, compute_class_we...</td>\n",
       "      <td>[[sklearn, compute_class_weight], [imblearn, R...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4346</th>\n",
       "      <td>zainabmuhammad_house-prices-prediction-ip-proj...</td>\n",
       "      <td>{(, seaborn, sns), (scipy, stats, ), (sklearn....</td>\n",
       "      <td>[[seaborn, sns], [scipy, stats], [sklearn, Sta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4347</th>\n",
       "      <td>zakirkhanaleemi_gemini-api-entrant-notebook.ipynb</td>\n",
       "      <td>{(, textwrap, ), (IPython.display, display, ),...</td>\n",
       "      <td>[[textwrap, textwrap], [IPython, display], [IP...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4348</th>\n",
       "      <td>zukhrufia_fork-of-tugas-algo-zukhru.ipynb</td>\n",
       "      <td>{}</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4349 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  fname  \\\n",
       "0                          aadyac_ingenium-level3.ipynb   \n",
       "1                  abaojiang_eda-on-game-progress.ipynb   \n",
       "2      abdallahelsayed22_image-segmentation-u-net.ipynb   \n",
       "3     abdallahwagih_plant-stress-identification-acc-...   \n",
       "4                  abdelrahmanmuhsen_semseg-tests.ipynb   \n",
       "...                                                 ...   \n",
       "4344                 yeohhanyi_cirrhosis-outcomes.ipynb   \n",
       "4345  yeohqiwei_credit-card-fraud-transaction-classi...   \n",
       "4346  zainabmuhammad_house-prices-prediction-ip-proj...   \n",
       "4347  zakirkhanaleemi_gemini-api-entrant-notebook.ipynb   \n",
       "4348          zukhrufia_fork-of-tugas-algo-zukhru.ipynb   \n",
       "\n",
       "                                                imports  \\\n",
       "0     {(, seaborn, sns), (, cv2, ), (, matplotlib.py...   \n",
       "1     {(, seaborn, sns), (typing, Any, ), (typing, U...   \n",
       "2     {(keras.layers, Conv2D, ), (tensorflow.keras.u...   \n",
       "3     {(tensorflow.keras.layers, Activation, ), (, w...   \n",
       "4     {(, tensorflow, tf), (keras.layers, Conv2D, ),...   \n",
       "...                                                 ...   \n",
       "4344  {(, tensorflow, tf), (sklearn.preprocessing, S...   \n",
       "4345  {(sklearn.utils.class_weight, compute_class_we...   \n",
       "4346  {(, seaborn, sns), (scipy, stats, ), (sklearn....   \n",
       "4347  {(, textwrap, ), (IPython.display, display, ),...   \n",
       "4348                                                 {}   \n",
       "\n",
       "                                              lib_alias  \n",
       "0     [[seaborn, sns], [cv2, cv2], [matplotlib, plt]...  \n",
       "1     [[seaborn, sns], [typing, Any], [typing, Union...  \n",
       "2     [[keras, Conv2D], [tensorflow, normalize], [ma...  \n",
       "3     [[tensorflow, Activation], [warnings, warnings...  \n",
       "4     [[tensorflow, tf], [keras, Conv2D], [tqdm, tqd...  \n",
       "...                                                 ...  \n",
       "4344  [[tensorflow, tf], [sklearn, StandardScaler], ...  \n",
       "4345  [[sklearn, compute_class_weight], [imblearn, R...  \n",
       "4346  [[seaborn, sns], [scipy, stats], [sklearn, Sta...  \n",
       "4347  [[textwrap, textwrap], [IPython, display], [IP...  \n",
       "4348                                                 []  \n",
       "\n",
       "[4349 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import imports_parser\n",
    "import pickle\n",
    "import config\n",
    "\n",
    "res1 = imports_parser.get_imports_nbs_static(config.path_kaggle_error_process.joinpath(\"k_error_nbs\"), imports_parser.get_imports_line_all)\n",
    "res_pd_1 = pd.DataFrame.from_dict(res1)\n",
    "res_pd_1[\"lib_alias\"] = res_pd_1.imports.apply(imports_parser.get_lib_alias)\n",
    "res_pd_1.to_excel(config.path_kaggle_error_process.joinpath(\"imports_all_info.xlsx\"), index=False, engine=\"xlsxwriter\")\n",
    "res_pd_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ad0b27bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_pd_1 = pd.read_excel(config.path_kaggle_error_process.joinpath(\"imports_all_info.xlsx\"))\n",
    "df_err = pd.read_excel(config.path_kaggle_error_process.joinpath('nberror_k_eid_p.xlsx'))\n",
    "df_err = pd.merge(df_err, res_pd_1, on=\"fname\", how=\"left\")\n",
    "df_err.to_excel(config.path_kaggle_error_process.joinpath('nberror_k_eid_p.xlsx'), index=False, engine='xlsxwriter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca943227",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
